from __future__ import annotations

import os
import json
import random
from itertools import combinations
from collections import defaultdict
from dataclasses import dataclass
from enum import Enum
from typing import (
    Set, List, Dict, Tuple, Union, Optional, Callable, Iterator, TypeAlias
)

import torch
from transformers import AutoTokenizer, AutoModel
from torch_geometric.data import HeteroData


# --- Types and constants ---

InteractionUnit = Tuple[int, int, int, int, int]  # (user, session, query, llm, response)
TensorOrEmbInit = Union["EmbInit", torch.Tensor]
EncodeFn = Callable[..., torch.Tensor]

NodeDict: TypeAlias = Dict[str, torch.Tensor]
EdgeIndexDict: TypeAlias = Dict["HeteroEdges", torch.Tensor]
EdgeBag: TypeAlias = Dict["HeteroEdges", List[Tuple[int, int, Optional[float]]]]

JSONL_SUFFIX = ".jsonl"
DTYPE = torch.float32


def _default_device() -> torch.device:
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")


# Global cache for sampling metadata, keyed by id(metadata).
# Each entry stores a pair: (metadata_list, user_to_entries).
_METADATA_INDEX_CACHE: Dict[
    int,
    Tuple[
        List[Tuple[InteractionUnit, InteractionUnit]],
        Dict[int, List[Tuple[InteractionUnit, InteractionUnit]]],
    ],
] = {}


# --- Enums ---

class EmbInit(str, Enum):
    ZEROS = "zero"
    ONES = "ones"
    RANDOM = "random"


class HeteroEdges(Tuple[str, str, str], Enum):
    U2S = ("user", "own", "session")
    U2Q = ("user", "ask", "query")
    U2R = ("user", "receive", "response")
    S2U = ("session", "owned by", "user")
    S2Q = ("session", "include", "query")
    S2R = ("session", "include", "response")
    S2L = ("session", "call", "llm")
    S1S2 = ("session", "next", "session")
    S2S1 = ("session", "prev", "session")
    Q2U = ("query", "asked by", "user")
    Q2S = ("query", "included by", "session")
    Q2R = ("query", "answered by", "response")
    Q2L = ("query", "to", "llm")
    Q1Q2 = ("query", "next", "query")
    Q2Q1 = ("query", "prev", "query")
    R2U = ("response", "back to", "user")
    R2S = ("response", "included by", "session")
    R2Q = ("response", "answered to", "query")
    R2L = ("response", "generated by", "llm")
    L2Q = ("llm", "receive", "query")
    L2R = ("llm", "generate", "response")
    L2S = ("llm", "response to", "session")


# --- Feature container ---

@dataclass
class HeteroFeature:
    """Container for dataset sizes and core feature tensors used in the heterograph."""
    num_users: int
    num_sessions: int
    num_queries: int
    num_responses: int
    num_llms: int

    query_emb: torch.Tensor      # [num_queries, emb_dim]
    llm_plm_emb: torch.Tensor    # [num_llms,   emb_dim]

    aggregation_type: str = "mean"
    emb_dim: int = 768
    user_emb: TensorOrEmbInit = EmbInit.ZEROS
    session_emb: TensorOrEmbInit = EmbInit.ZEROS
    response_emb: TensorOrEmbInit = EmbInit.ZEROS
    eps: float = 1e-8

    plm_name: Optional[str] = None
    plm_encode: Optional[EncodeFn] = None

    def __post_init__(self) -> None:
        for k in ("num_users", "num_sessions", "num_queries", "num_responses", "num_llms"):
            v = getattr(self, k)
            if not isinstance(v, int) or v <= 0:
                raise ValueError(f"{k} must be a positive int, got {v}")
        if not (isinstance(self.query_emb, torch.Tensor) and self.query_emb.shape == (self.num_queries, self.emb_dim)):
            raise ValueError(
                f"query_emb must be [{self.num_queries}, {self.emb_dim}], got {tuple(self.query_emb.shape)}"
            )
        if not (isinstance(self.llm_plm_emb, torch.Tensor) and self.llm_plm_emb.shape == (self.num_llms, self.emb_dim)):
            raise ValueError(
                f"llm_plm_emb must be [{self.num_llms}, {self.emb_dim}], got {tuple(self.llm_plm_emb.shape)}"
            )

    def _tinfo(self, t: Optional[torch.Tensor]) -> str:
        return "None" if t is None else f"shape={tuple(t.shape)}, dtype={t.dtype}, device={t.device}"

    def _init_info(self, val: TensorOrEmbInit, rows: int) -> str:
        if isinstance(val, torch.Tensor):
            ok = (val.dim() == 2 and val.size(0) == rows and val.size(1) == self.emb_dim)
            shape = tuple(val.shape)
            suffix = "" if ok else " (mismatch!)"
            return f"Tensor[{shape}, dtype={val.dtype}, device={val.device}]{suffix}"
        return f"init={val.value}"

    def summary(self) -> str:
        if self.plm_encode is None:
            enc_name = None
        else:
            enc_name = getattr(self.plm_encode, "__name__", self.plm_encode.__class__.__name__)
        return "\n".join(
            [
                "HeteroFeatureConfig(",
                (
                    "  counts: users={u}, sessions={s}, queries={q}, "
                    "responses={r}, llms={l}"
                ).format(
                    u=self.num_users,
                    s=self.num_sessions,
                    q=self.num_queries,
                    r=self.num_responses,
                    l=self.num_llms,
                ),
                f"  emb_dim={self.emb_dim}",
                f"  user_emb:    {self._init_info(self.user_emb, self.num_users)}",
                f"  session_emb: {self._init_info(self.session_emb, self.num_sessions)}",
                f"  query_emb:   {self._tinfo(self.query_emb)}",
                f"  response_emb:{self._init_info(self.response_emb, self.num_responses)}",
                f"  llm_plm_emb: {self._tinfo(self.llm_plm_emb)}",
                f"  plm: name='{self.plm_name}', encode={enc_name}",
                ")",
            ]
        )

    __repr__ = __str__ = summary


# --- PLM encoding ---

def make_plm_encode(plm_name: str) -> Callable[[List[str]], torch.Tensor]:
    """
    Construct a mean-pooled Hugging Face encoder.

    The returned function maps a list of texts to a tensor of shape [batch_size, hidden_dim]
    with dtype float32.
    """
    device = _default_device()
    tokenizer = AutoTokenizer.from_pretrained(plm_name)
    model = AutoModel.from_pretrained(plm_name).to(device).eval()

    def encode_fn(texts: List[str]) -> torch.Tensor:
        with torch.no_grad():
            toks = tokenizer(
                texts,
                max_length=512,
                padding=True,
                truncation=True,
                return_tensors="pt",
            )
            toks = {k: v.to(device) for k, v in toks.items()}
            out = model(**toks)
            hidden = out.last_hidden_state                   # Shape: [batch_size, sequence_length, hidden_dim].
            attn = toks["attention_mask"].bool()             # Shape: [batch_size, sequence_length].
            hidden = hidden.masked_fill(~attn[..., None], 0) # Mask out padding positions.
            denom = attn.sum(dim=1, keepdim=True).clamp_min(1)
            return (hidden.sum(dim=1) / denom).to(dtype=DTYPE)

    return encode_fn


# --- Edge helpers ---

def add_edge(
    edges_bag: EdgeBag,
    edge_type: HeteroEdges,
    src: Optional[int],
    dst: Optional[int],
    weight: Optional[float] = None,
) -> None:
    """Append an edge (src → dst) to the edge bag if both indices are valid."""
    if src is None or dst is None:
        return
    edges_bag[edge_type].append((src, dst, weight))


def build_interaction_edges(
    edges_bag: EdgeBag,
    interaction1: InteractionUnit,
    interaction2: InteractionUnit,
    prev_s1_idx: Optional[int],
    prev_s2_idx: Optional[int],
) -> None:
    """
    Add edges for a pair of interactions.

    This includes:
    - Session → user edges.
    - Query / response / LLM → session edges.
    - Temporal edges linking to previous sessions when available.
    """
    u1, s1, q1, m1, r1 = interaction1
    u2, s2, q2, m2, r2 = interaction2

    for (etype, src, dst) in (
        (HeteroEdges.S2U, s1, u1),
        (HeteroEdges.S2U, s2, u2),
        (HeteroEdges.Q2S, q1, s1),
        (HeteroEdges.Q2S, q2, s2),
        (HeteroEdges.L2S, m1, s1),
        (HeteroEdges.L2S, m2, s2),
        (HeteroEdges.R2S, r1, s1),
        (HeteroEdges.R2S, r2, s2),
        (HeteroEdges.S2S1, s1, prev_s1_idx),
        (HeteroEdges.S2S1, s2, prev_s2_idx),
    ):
        add_edge(edges_bag, etype, src, dst)


def build_graph_edges(
    edges_bag: EdgeBag,
    device: torch.device,
) -> EdgeIndexDict:
    """
    Convert edge triplets into PyTorch edge_index tensors of shape [2, num_edges],
    placed on the specified device.
    """
    edge_index_dict: EdgeIndexDict = {}
    for etype, triples in edges_bag.items():
        if not triples:
            continue
        src, dst, _ = zip(*triples)
        src_tensor = torch.tensor(src, dtype=torch.long, device=device)
        dst_tensor = torch.tensor(dst, dtype=torch.long, device=device)
        edge_index_dict[etype] = torch.stack((src_tensor, dst_tensor), dim=0)
    return edge_index_dict


# --- Edge views / session helpers ---

def _as_edges_dict(graph: Union[HeteroData, EdgeIndexDict]) -> EdgeIndexDict:
    """
    Return a mapping {HeteroEdges: edge_index} from either a HeteroData instance
    or an existing EdgeIndexDict.
    """
    if isinstance(graph, HeteroData):
        out: EdgeIndexDict = {}
        for et in graph.edge_types:
            ei = graph[et].edge_index
            if ei is None:
                continue
            try:
                et_enum = HeteroEdges(et)  # Convert ('src', 'rel', 'dst') to the corresponding enum.
            except ValueError:
                continue
            out[et_enum] = ei
        return out
    return graph


def build_prev_session_map(graph: Union[HeteroData, EdgeIndexDict]) -> Dict[int, int]:
    """
    Build a mapping from current_session → previous_session using S2S1 edges.

    If no S2S1 edges are present, an empty dictionary is returned.
    """
    edges = _as_edges_dict(graph)
    s2s1 = edges.get(HeteroEdges.S2S1)
    if s2s1 is None:
        return {}
    curr, prev = s2s1[0].tolist(), s2s1[1].tolist()
    return dict(zip(curr, prev))


def build_visible_edges(
    graph: Union[HeteroData, EdgeIndexDict],
    visible_list: List[Tuple[InteractionUnit, InteractionUnit]],
    multi_turn: bool,
    device: torch.device,
) -> EdgeIndexDict:
    """
    Construct an edge_index dictionary for a set of visible interactions.

    When multi_turn is True, previous sessions are linked if they are also visible.
    Otherwise, only per-interaction edges are added without temporal links.
    """
    visible_edges_bag: EdgeBag = defaultdict(list)

    if multi_turn:
        sampled_sessions = {i1[1] for i1, _ in visible_list} | {i2[1] for _, i2 in visible_list}
        prev_of = build_prev_session_map(graph)

        for i1, i2 in visible_list:
            s1, s2 = i1[1], i2[1]
            p1 = prev_of.get(s1)
            p2 = prev_of.get(s2)
            prev_s1_idx = p1 if (p1 is not None and p1 in sampled_sessions) else None
            prev_s2_idx = p2 if (p2 is not None and p2 in sampled_sessions) else None
            build_interaction_edges(visible_edges_bag, i1, i2, prev_s1_idx, prev_s2_idx)
    else:
        for i1, i2 in visible_list:
            build_interaction_edges(visible_edges_bag, i1, i2, None, None)

    return build_graph_edges(visible_edges_bag, device)


# --- JSONL parsing/building ---

def parse_jsonl_groups(path: str) -> Iterator[List[dict]]:
    """
    Yield consecutive groups of entries from a JSONL file.

    Each group has length ≥ 2 and shares the same (question_id, turn, judge).
    """
    loads = json.loads
    with open(path, "r", encoding="utf-8") as f:
        group: List[dict] = []
        key = None
        for line in f:
            e = loads(line)
            # Raises KeyError intentionally if any required key is missing.
            curr = (e["question_id"], e["turn"], e["judge"])
            if key is None:
                key = curr
                group = [e]
                continue
            if curr == key:
                group.append(e)
            else:
                assert len(group) >= 2, f"Group size <2 for key={key}"
                yield group
                key = curr
                group = [e]
        if group:
            assert len(group) >= 2, f"Group size <2 for key={key}"
            yield group


def parse_jsonl_pairs(path: str) -> Iterator[Tuple[dict, dict]]:
    """
    Backward-compatible parser that expands each group into all 2-combinations
    of entries.
    """
    for g in parse_jsonl_groups(path):
        for a, b in combinations(g, 2):
            yield a, b


def build_nodes_from_groups(groups: Iterator[List[dict]]):
    """
    Build node dictionaries, embeddings, ratings, edges, and metadata
    from grouped JSONL entries.
    """
    users: Dict[int, str] = {}
    llms: Dict[int, str] = {}
    queries: Dict[int, str] = {}
    responses: Dict[int, str] = {}

    user_to_idx: Dict[str, int] = {}
    llm_to_idx: Dict[str, int] = {}

    query_emb: List[List[float]] = []
    llm_emb: List[List[float]] = []
    ratings: List[float] = []

    edges_buffer: EdgeBag = defaultdict(list)
    metadata: Set[Tuple[InteractionUnit, InteractionUnit]] = set()
    meta_add = metadata.add
    add_interaction_edges = build_interaction_edges

    plm_name: Optional[str] = None
    session_cnt = 0

    for g in groups:
        # Check basic invariants (these should already be guaranteed by the parser).
        qids = {e["question_id"] for e in g}
        turns = {e["turn"] for e in g}
        judges = {e["judge"] for e in g}
        assert len(qids) == len(turns) == len(judges) == 1, "Group invariants violated"

        u_name = g[0]["judge"]
        u_idx = user_to_idx.get(u_name)
        if u_idx is None:
            u_idx = len(user_to_idx)
            user_to_idx[u_name] = u_idx
            users[u_idx] = u_name

        # Compute LLM identifiers for this group.
        m_idx_list: List[int] = []
        for e in g:
            m_name = e["model"]
            mid = llm_to_idx.get(m_name)
            if mid is None:
                mid = len(llm_to_idx)
                llm_to_idx[m_name] = mid
                llms[mid] = m_name
                llm_emb.append(e["model_emb"])
            m_idx_list.append(mid)

        # Conversation turns must all have the same length across models in the group.
        conv_lists = [e["conversation"] for e in g]
        lengths = {len(c) for c in conv_lists}
        assert len(lengths) == 1, f"Conversation length mismatch in group (judge={u_name})"

        # Track the previous session identifier for each model track.
        prev_s: List[Optional[int]] = [None] * len(g)

        for step in zip(*conv_lists):  # One tuple per turn, length == len(g).
            # Build interactions per model for this turn.
            interactions: List[InteractionUnit] = []
            for j, t in enumerate(step):
                s = session_cnt
                session_cnt += 1

                q = len(query_emb)
                queries[q] = t["query"]
                query_emb.append(t["query_emb"])

                r = len(responses)
                responses[r] = t.get("response", "None")
                ratings.append(float(t["rating"]))

                m = m_idx_list[j]
                i: InteractionUnit = (u_idx, s, q, m, r)
                interactions.append(i)

                # Add per-interaction edges and temporal edges within this model track.
                # This adds S2U, Q2S, L2S, R2S, and S2S1 edges.
                add_interaction_edges(edges_buffer, i, i, prev_s[j], prev_s[j])
                prev_s[j] = s

            # Add pairwise metadata for this turn (all 2-combinations of interactions).
            for a, b in combinations(interactions, 2):
                meta_add((a, b))

        if plm_name is None and "encoder" in g[0]:
            plm_name = g[0]["encoder"]

    return (
        users,
        llms,
        queries,
        responses,
        query_emb,
        llm_emb,
        ratings,
        metadata,
        edges_buffer,
        plm_name,
        session_cnt,
    )


# --- Helpers ---

def _normalize_ratings(r_score: List[float], device: torch.device) -> torch.Tensor:
    """
    Apply min–max normalization to a list of ratings.

    Returns a tensor of shape [num_ratings, 1] with values scaled into [0, 1].
    """
    x = torch.tensor(r_score, dtype=DTYPE, device=device).unsqueeze(-1)
    x_min = x.min()
    x_max = x.max()
    return (x - x_min) / (x_max - x_min + 1e-8)


# --- Build from JSONL ---

def build_config_from_jsonl(path: str):
    """
    Build tensors and dictionaries from a JSONL file.

    Returns:
        A tuple (config, nodes, edge_index_dict, users, queries, responses,
        ratings, llms, metadata, device).
    """
    device = _default_device()
    (
        users,
        llms,
        queries,
        responses,
        q_emb,
        l_emb,
        r_score,
        meta,
        edge_buf,
        plm,
        sess_n,
    ) = build_nodes_from_groups(parse_jsonl_groups(path))

    assert sess_n > 0, "Empty dataset."
    emb_dim = len(q_emb[0])

    edge_index_dict = build_graph_edges(edge_buf, device)
    ratings = _normalize_ratings(r_score, device)

    x_user = torch.zeros((len(users), emb_dim), dtype=DTYPE, device=device)
    x_session = torch.zeros((sess_n, emb_dim), dtype=DTYPE, device=device)
    x_query = torch.tensor(q_emb, dtype=DTYPE, device=device)
    x_llm = torch.tensor(l_emb, dtype=DTYPE, device=device)
    x_response = ratings * torch.ones((len(responses), emb_dim), dtype=DTYPE, device=device)

    nodes: NodeDict = {
        "user": x_user,
        "session": x_session,
        "response": x_response,
        "query": x_query,
        "llm": x_llm,
    }

    config = HeteroFeature(
        num_users=len(users),
        num_sessions=sess_n,
        num_queries=len(q_emb),
        num_responses=len(responses),
        num_llms=len(l_emb),
        user_emb=EmbInit.ZEROS,
        session_emb=EmbInit.ZEROS,
        response_emb=EmbInit.ZEROS,
        llm_plm_emb=x_llm,
        query_emb=x_query,
        emb_dim=emb_dim,
        plm_name=plm,
        plm_encode=(make_plm_encode(plm) if plm is not None else None),
        aggregation_type="mean",
    )

    return (
        config,
        nodes,
        edge_index_dict,
        users,
        queries,
        responses,
        ratings,
        llms,
        meta,
        device,
    )


# --- Build/load wrapper ---

def build_config(path: str, ckpt_path: str = None):
    """
    Build configuration from a JSONL file (and optionally save a checkpoint)
    or load an existing checkpoint from disk.
    """
    device = _default_device()

    # JSONL → fresh build (optionally save to a checkpoint).
    if path.endswith(JSONL_SUFFIX):
        dataset_name = os.path.basename(os.path.dirname(path))
        result = build_config_from_jsonl(path)
        (
            config,
            nodes,
            edge_index_dict,
            user_dict,
            query_dict,
            response_dict,
            ratings,
            llm_dict,
            metadata,
            device,
        ) = result

        if ckpt_path is not None:
            # If ckpt_path ends with ".pt", treat it as a file path; otherwise, treat it as a directory.
            if ckpt_path.endswith(".pt"):
                save_path = ckpt_path
                os.makedirs(os.path.dirname(save_path) or ".", exist_ok=True)
            else:
                os.makedirs(ckpt_path, exist_ok=True)
                save_path = os.path.join(ckpt_path, f"{dataset_name}.pt")

            torch.save(
                {
                    "version": "v1",
                    "config": {
                        "num_users": config.num_users,
                        "num_sessions": config.num_sessions,
                        "num_queries": config.num_queries,
                        "num_responses": config.num_responses,
                        "num_llms": config.num_llms,
                        "emb_dim": config.emb_dim,
                        "plm_name": config.plm_name,
                        "aggregation_type": config.aggregation_type,
                    },
                    "nodes": {k: v.cpu() for k, v in nodes.items()},
                    "edges": {etype.name: v.cpu() for etype, v in edge_index_dict.items()},
                    "user_dict": user_dict,
                    "query_dict": query_dict,
                    "response_dict": response_dict,
                    "llm_dict": llm_dict,
                    "metadata": list(metadata),
                    "ratings": ratings.cpu(),
                },
                save_path,
            )

        return result

    # Load branch: restore tensors from a checkpoint.
    if os.path.isdir(path):
        dataset_name = os.path.basename(os.path.normpath(path))
        ckpt_file = os.path.join(path, f"{dataset_name}.pt")
    else:
        ckpt_file = path

    if not os.path.exists(ckpt_file):
        raise FileNotFoundError(f"No checkpoint found at {ckpt_file}")

    ckpt = torch.load(ckpt_file, map_location=device)
    cfg = ckpt["config"]

    nodes: NodeDict = {k: v.to(device) for k, v in ckpt["nodes"].items()}
    plm_name = cfg["plm_name"]
    plm_encode = make_plm_encode(plm_name) if plm_name is not None else None

    config = HeteroFeature(
        num_users=cfg["num_users"],
        num_sessions=cfg["num_sessions"],
        num_queries=cfg["num_queries"],
        num_responses=cfg["num_responses"],
        num_llms=cfg["num_llms"],
        query_emb=nodes["query"],
        llm_plm_emb=nodes["llm"],
        emb_dim=cfg["emb_dim"],
        plm_name=plm_name,
        plm_encode=plm_encode,
        aggregation_type=cfg["aggregation_type"],
    )

    edges: EdgeIndexDict = {
        HeteroEdges[name]: v.to(device) for name, v in ckpt["edges"].items()
    }
    metadata = set(tuple(map(tuple, x)) for x in ckpt["metadata"])
    ratings = ckpt["ratings"].to(device)

    return (
        config,
        nodes,
        edges,
        ckpt["user_dict"],
        ckpt["query_dict"],
        ckpt["response_dict"],
        ratings,
        ckpt["llm_dict"],
        metadata,
        device,
    )


# --- Sampling and PyG graph construction ---

def sample_metadata(
    metadata: Set[Tuple[InteractionUnit, InteractionUnit]],
    visible_count: int = 256,
    predict_count: int = 32,
    min_record_per_user: int = 10,
    seed: int = None,
) -> Tuple[List[Tuple[InteractionUnit, InteractionUnit]], List[Tuple[InteractionUnit, InteractionUnit]]]:
    """
    Split metadata into visible and prediction subsets while enforcing a per-user minimum.

    The function ensures that each user has at least `min_record_per_user` entries in the
    visible set before filling up the remaining slots and drawing a prediction subset.
    """
    rnd = random.Random(seed)
    rnd_sample = rnd.sample
    rnd_shuffle = rnd.shuffle

    meta_id = id(metadata)
    cached = _METADATA_INDEX_CACHE.get(meta_id)
    if cached is None:
        # First time this metadata object is seen: build and cache the index.
        metadata_list = list(metadata)
        user_to_entries: defaultdict[int, List[Tuple[InteractionUnit, InteractionUnit]]] = defaultdict(list)
        for e in metadata_list:
            user_to_entries[e[0][0]].append(e)
        _METADATA_INDEX_CACHE[meta_id] = (metadata_list, user_to_entries)
    else:
        metadata_list, user_to_entries = cached

    total = len(metadata_list)
    assert visible_count + predict_count <= total, (
        f"visible_count({visible_count}) + predict_count({predict_count}) > total({total})"
    )

    visible_set = set()
    pool: List[Tuple[InteractionUnit, InteractionUnit]] = []

    # Enforce per-user minimum in the visible set.
    for u, entries in user_to_entries.items():
        if len(entries) < min_record_per_user:
            raise AssertionError(
                f"User {u} has only {len(entries)} records < min_record_per_user={min_record_per_user}"
            )
        sampled = rnd_sample(entries, min_record_per_user)
        visible_set.update(sampled)
        pool.extend(x for x in entries if x not in sampled)

    visible_list = list(visible_set)
    vis_len = len(visible_list)

    if vis_len > visible_count:
        rnd_shuffle(visible_list)
        overflow = visible_list[visible_count:]
        visible_list = visible_list[:visible_count]
        pool.extend(overflow)
    elif vis_len < visible_count:
        need = visible_count - vis_len
        if len(pool) < need:
            raise AssertionError("Not enough pool entries to reach visible_count.")
        rnd_shuffle(pool)
        visible_list += pool[:need]
        pool = pool[need:]

    # Build the prediction pool.
    if len(pool) >= predict_count:
        remaining = pool
    else:
        pool_set = set(pool)
        remaining = pool + [
            e for e in metadata_list
            if e not in visible_set and e not in pool_set
        ]

    assert len(remaining) >= predict_count, "Not enough remaining entries to sample prediction set."
    predict_list = rnd_sample(remaining, predict_count)
    return visible_list, predict_list


def build_hetero_data(nodes: NodeDict, edge_index_dict: EdgeIndexDict) -> HeteroData:
    """
    Create a PyTorch Geometric HeteroData object from node feature tensors
    and a dictionary of edge_index tensors.
    """
    data = HeteroData()
    for ntype, x in nodes.items():
        data[ntype].x = x
    for etype, edge_index in edge_index_dict.items():
        src, rel, dst = etype.value
        data[(src, rel, dst)].edge_index = edge_index
    return data
