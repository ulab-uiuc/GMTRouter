from __future__ import annotations

import os
import json
import random
from collections import defaultdict
from dataclasses import dataclass
from enum import Enum
from typing import (
    Set, List, Dict, Tuple, Union, Optional, Callable, Iterator, TypeAlias
)

import torch
from transformers import AutoTokenizer, AutoModel
from torch_geometric.data import HeteroData


# --- Types and constants ---

InteractionUnit = Tuple[int, int, int, int, int]  # (user, session, query, llm, response)
TensorOrEmbInit = Union["EmbInit", torch.Tensor]
EncodeFn = Callable[..., torch.Tensor]

NodeDict: TypeAlias = Dict[str, torch.Tensor]
EdgeIndexDict: TypeAlias = Dict["HeteroEdges", torch.Tensor]
EdgeBag: TypeAlias = Dict["HeteroEdges", List[Tuple[int, int, Optional[float]]]]

JSONL_SUFFIX = ".jsonl"
DTYPE = torch.float32


def _default_device() -> torch.device:
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")


# --- Enumerations ---

class EmbInit(str, Enum):
    ZEROS = "zero"
    ONES = "ones"
    RANDOM = "random"


class HeteroEdges(Tuple[str, str, str], Enum):
    U2S = ("user", "own", "session")
    U2Q = ("user", "ask", "query")
    U2R = ("user", "receive", "response")
    S2U = ("session", "owned by", "user")
    S2Q = ("session", "include", "query")
    S2R = ("session", "include", "response")
    S2L = ("session", "call", "llm")
    S1S2 = ("session", "next", "session")
    S2S1 = ("session", "prev", "session")
    Q2U = ("query", "asked by", "user")
    Q2S = ("query", "included by", "session")
    Q2R = ("query", "answered by", "response")
    Q2L = ("query", "to", "llm")
    Q1Q2 = ("query", "next", "query")
    Q2Q1 = ("query", "prev", "query")
    R2U = ("response", "back to", "user")
    R2S = ("response", "included by", "session")
    R2Q = ("response", "answered to", "query")
    R2L = ("response", "generated by", "llm")
    L2Q = ("llm", "receive", "query")
    L2R = ("llm", "generate", "response")
    L2S = ("llm", "response to", "session")


# --- Feature container ---

@dataclass
class HeteroFeature:
    """Container for dataset statistics and the corresponding feature tensors."""

    num_users: int
    num_sessions: int
    num_queries: int
    num_responses: int
    num_llms: int

    query_emb: torch.Tensor      # [num_queries, emb_dim]
    llm_plm_emb: torch.Tensor    # [num_llms,   emb_dim]

    aggregation_type: str = "mean"
    emb_dim: int = 768
    user_emb: TensorOrEmbInit = EmbInit.ZEROS
    session_emb: TensorOrEmbInit = EmbInit.ZEROS
    response_emb: TensorOrEmbInit = EmbInit.ZEROS
    eps: float = 1e-8

    plm_name: Optional[str] = None
    plm_encode: Optional[EncodeFn] = None

    def __post_init__(self):
        for k in ("num_users", "num_sessions", "num_queries", "num_responses", "num_llms"):
            v = getattr(self, k)
            if not isinstance(v, int) or v <= 0:
                raise ValueError(f"{k} must be a positive int, got {v}")
        if not (isinstance(self.query_emb, torch.Tensor) and self.query_emb.shape == (self.num_queries, self.emb_dim)):
            raise ValueError(f"query_emb must be [{self.num_queries}, {self.emb_dim}], got {tuple(self.query_emb.shape)}")
        if not (isinstance(self.llm_plm_emb, torch.Tensor) and self.llm_plm_emb.shape == (self.num_llms, self.emb_dim)):
            raise ValueError(f"llm_plm_emb must be [{self.num_llms}, {self.emb_dim}], got {tuple(self.llm_plm_emb.shape)}")

    def _tinfo(self, t: Optional[torch.Tensor]) -> str:
        return "None" if t is None else f"shape={tuple(t.shape)}, dtype={t.dtype}, device={t.device}"

    def _init_info(self, val: TensorOrEmbInit, rows: int) -> str:
        if isinstance(val, torch.Tensor):
            ok = (val.dim() == 2 and val.size(0) == rows and val.size(1) == self.emb_dim)
            shape = tuple(val.shape)
            return f"Tensor[{shape}, dtype={val.dtype}, device={val.device}]{'' if ok else ' (mismatch!)'}"
        return f"init={val.value}"

    def summary(self) -> str:
        enc_name = getattr(self.plm_encode, "__name__", self.plm_encode.__class__.__name__) if self.plm_encode else None
        return "\n".join([
            "HeteroFeatureConfig(",
            f"  counts: users={self.num_users}, sessions={self.num_sessions}, queries={self.num_queries}, responses={self.num_responses}, llms={self.num_llms}",
            f"  emb_dim={self.emb_dim}",
            f"  user_emb:    {self._init_info(self.user_emb, self.num_users)}",
            f"  session_emb: {self._init_info(self.session_emb, self.num_sessions)}",
            f"  query_emb:   {self._tinfo(self.query_emb)}",
            f"  response_emb:{self._init_info(self.response_emb, self.num_responses)}",
            f"  llm_plm_emb: {self._tinfo(self.llm_plm_emb)}",
            f"  plm: name='{self.plm_name}', encode={enc_name}",
            ")"
        ])

    __repr__ = __str__ = summary


# --- PLM encoding ---

def make_plm_encode(plm_name: str) -> Callable[[List[str]], torch.Tensor]:
    """Construct a mean-pooled Hugging Face encoder mapping texts to [batch_size, hidden_dim] float32 tensors."""
    device = _default_device()
    tokenizer = AutoTokenizer.from_pretrained(plm_name)
    model = AutoModel.from_pretrained(plm_name).to(device).eval()

    def encode_fn(texts: List[str]) -> torch.Tensor:
        with torch.no_grad():
            toks = tokenizer(texts, max_length=512, padding=True, truncation=True, return_tensors="pt")
            toks = {k: v.to(device) for k, v in toks.items()}
            out = model(**toks)
            hidden = out.last_hidden_state                   # [B,T,H]
            attn = toks["attention_mask"].bool()             # [B,T]
            hidden = hidden.masked_fill(~attn[..., None], 0) # mask padding
            denom = attn.sum(dim=1, keepdim=True).clamp_min(1)
            return (hidden.sum(dim=1) / denom).to(dtype=DTYPE)
    return encode_fn


# --- Edge helpers ---

def add_edge(
    edges_bag: EdgeBag,
    edge_type: HeteroEdges,
    src: Optional[int],
    dst: Optional[int],
    weight: Optional[float] = None
) -> None:
    """Append a directed edge (src → dst) to the buffer if both node indices are valid."""
    if src is None or dst is None:
        return
    edges_bag[edge_type].append((src, dst, weight))


def build_interaction_edges(
    edges_bag: EdgeBag,
    interaction1: InteractionUnit,
    interaction2: InteractionUnit,
    prev_s1_idx: Optional[int],
    prev_s2_idx: Optional[int],
) -> None:
    """
    Add edges corresponding to a pair of interactions.

    This includes session-to-user edges, query/LLM/response-to-session edges,
    and optional temporal links to previous sessions.
    """
    u1, s1, q1, m1, r1 = interaction1
    u2, s2, q2, m2, r2 = interaction2

    for (etype, src, dst) in (
        (HeteroEdges.S2U, s1, u1),
        (HeteroEdges.S2U, s2, u2),
        (HeteroEdges.Q2S, q1, s1),
        (HeteroEdges.Q2S, q2, s2),
        (HeteroEdges.L2S, m1, s1),
        (HeteroEdges.L2S, m2, s2),
        (HeteroEdges.R2S, r1, s1),
        (HeteroEdges.R2S, r2, s2),
        (HeteroEdges.S2S1, s1, prev_s1_idx),
        (HeteroEdges.S2S1, s2, prev_s2_idx),
    ):
        add_edge(edges_bag, etype, src, dst)


def build_graph_edges(
    edges_bag: EdgeBag,
    device: torch.device
) -> EdgeIndexDict:
    """Convert in-memory edge triplets into PyTorch Geometric `edge_index` tensors of shape [2, num_edges] on the specified device."""
    edge_index_dict: EdgeIndexDict = {}
    for etype, triples in edges_bag.items():
        if not triples:
            continue
        src, dst, _ = zip(*triples)
        edge_index_dict[etype] = torch.stack(
            (
                torch.tensor(src, dtype=torch.long, device=device),
                torch.tensor(dst, dtype=torch.long, device=device),
            ),
            dim=0,
        )
    return edge_index_dict


# --- Edge views / session helpers ---

def _as_edges_dict(graph: Union[HeteroData, EdgeIndexDict]) -> EdgeIndexDict:
    """Return a mapping from `HeteroEdges` to `edge_index` tensors given a `HeteroData` object or an existing dictionary."""
    if isinstance(graph, HeteroData):
        out: EdgeIndexDict = {}
        for et in graph.edge_types:
            ei = graph[et].edge_index
            if ei is None:
                continue
            try:
                et_enum = HeteroEdges(et)  # ('src','rel','dst') -> enum
            except ValueError:
                continue
            out[et_enum] = ei
        return out
    return graph


def build_prev_session_map(graph: Union[HeteroData, EdgeIndexDict]) -> Dict[int, int]:
    """Construct a mapping from the current session index to the previous session index using `S2S1` edges."""
    edges = _as_edges_dict(graph)
    s2s1 = edges.get(HeteroEdges.S2S1)
    if s2s1 is None:
        return {}
    curr, prev = s2s1[0].tolist(), s2s1[1].tolist()
    return dict(zip(curr, prev))


def build_visible_edges(
    graph: Union[HeteroData, EdgeIndexDict],
    visible_list: List[Tuple[InteractionUnit, InteractionUnit]],
    multi_turn: bool,
    device: torch.device,
) -> EdgeIndexDict:
    """
    Build an `edge_index` dictionary restricted to a set of visible interaction pairs.

    When `multi_turn` is True, previous sessions are linked only if they are also part of the sampled set.
    """
    visible_edges_bag: EdgeBag = defaultdict(list)

    if multi_turn:
        sampled_sessions = {i1[1] for i1, _ in visible_list} | {i2[1] for _, i2 in visible_list}
        prev_of = build_prev_session_map(graph)

        for i1, i2 in visible_list:
            s1, s2 = i1[1], i2[1]
            p1, p2 = prev_of.get(s1), prev_of.get(s2)
            prev_s1_idx = p1 if (p1 is not None and p1 in sampled_sessions) else None
            prev_s2_idx = p2 if (p2 is not None and p2 in sampled_sessions) else None
            build_interaction_edges(visible_edges_bag, i1, i2, prev_s1_idx, prev_s2_idx)
    else:
        for i1, i2 in visible_list:
            build_interaction_edges(visible_edges_bag, i1, i2, None, None)

    return build_graph_edges(visible_edges_bag, device)


# --- JSONL parsing/building ---

def parse_jsonl_pairs(path: str) -> Iterator[Tuple[dict, dict]]:
    """Yield consecutive pairs of JSON objects `(entry1, entry2)` from a JSONL file."""
    with open(path, "r", encoding="utf-8") as f:
        it = iter(f)
        for line1 in it:
            line2 = next(it, None)
            if line2 is None:
                break
            yield json.loads(line1), json.loads(line2)


def build_nodes_from_pairs(pairs: Iterator[Tuple[dict, dict]]):
    """
    Construct node dictionaries, feature matrices, rating vectors, edge buffers, and metadata from paired JSON entries.
    """
    users: Dict[int, str] = {}
    llms: Dict[int, str] = {}
    queries: Dict[int, str] = {}
    responses: Dict[int, str] = {}

    user_to_idx: Dict[str, int] = {}
    llm_to_idx: Dict[str, int] = {}

    query_emb: List[List[float]] = []
    llm_emb: List[List[float]] = []
    ratings: List[float] = []

    edges_buffer: EdgeBag = defaultdict(list)
    metadata: Set[Tuple[InteractionUnit, InteractionUnit]] = set()

    plm_name: Optional[str] = None
    session_cnt = 0

    for e1, e2 in pairs:
        assert e1["question_id"] == e2["question_id"], \
            f'Inconsistent jsonl structure: mismatch question ID: {e1["question_id"]} vs {e2["question_id"]}'
        assert e1["turn"] == e2["turn"], \
            f'Inconsistent jsonl structure with number of turns mismatch: {e1["turn"]} - {e2["turn"]}'

        u1 = e1["judge"]; u2 = e2["judge"]
        assert u1 == u2, f'Inconsistent jsonl structure with user name mismatch: {u1} - {u2}'
        u_idx = user_to_idx.get(u1)
        if u_idx is None:
            u_idx = len(user_to_idx); user_to_idx[u1] = u_idx; users[u_idx] = u1

        l1 = e1["model"]; l2 = e2["model"]
        if l1 not in llm_to_idx:
            idx = len(llm_to_idx); llm_to_idx[l1] = idx; llms[idx] = l1; llm_emb.append(e1["model_emb"])
        if l2 not in llm_to_idx:
            idx = len(llm_to_idx); llm_to_idx[l2] = idx; llms[idx] = l2; llm_emb.append(e2["model_emb"])
        m1 = llm_to_idx[l1]; m2 = llm_to_idx[l2]

        prev1: Optional[int] = None
        prev2: Optional[int] = None
        for t1, t2 in zip(e1["conversation"], e2["conversation"]):
            s1 = session_cnt; s2 = session_cnt + 1; session_cnt += 2
            q1 = len(query_emb); q2 = q1 + 1
            queries[q1] = t1["query"]; queries[q2] = t2["query"]
            query_emb.extend([t1["query_emb"], t2["query_emb"]])
            r1 = len(responses); r2 = r1 + 1
            responses[r1] = t1.get("response", "None")
            responses[r2] = t2.get("response", "None")
            ratings.append(float(t1["rating"])); ratings.append(float(t2["rating"]))

            i1 = (u_idx, s1, q1, m1, r1)
            i2 = (u_idx, s2, q2, m2, r2)
            metadata.add((i1, i2))
            build_interaction_edges(edges_buffer, i1, i2, prev1, prev2)
            prev1, prev2 = s1, s2

        if plm_name is None and "encoder" in e1:
            plm_name = e1["encoder"]

    return users, llms, queries, responses, query_emb, llm_emb, ratings, metadata, edges_buffer, plm_name, session_cnt


# --- Helpers ---

def _normalize_ratings(r_score: List[float], device: torch.device) -> torch.Tensor:
    """Apply min–max normalization to the provided ratings and return a tensor of shape [num_ratings, 1] in the range [0, 1]."""
    x = torch.tensor(r_score, dtype=DTYPE, device=device).unsqueeze(-1)
    return (x - x.min()) / (x.max() - x.min() + 1e-8)


# --- Build from JSONL ---

def build_config_from_jsonl(path: str):
    """
    Build tensors, dictionaries, graph edges, and configuration objects from a JSONL file.

    Returns (config, nodes, edges, user_dict, query_dict, response_dict, ratings, llm_dict, metadata, device).
    """
    device = _default_device()
    (users, llms, queries, responses, q_emb, l_emb, r_score,
     meta, edge_buf, plm, sess_n) = build_nodes_from_pairs(parse_jsonl_pairs(path))

    assert sess_n > 0, "Empty dataset."
    emb_dim = len(q_emb[0])

    edge_index_dict = build_graph_edges(edge_buf, device)
    ratings = _normalize_ratings(r_score, device)

    x_user = torch.zeros((len(users), emb_dim), dtype=DTYPE, device=device)
    x_session = torch.zeros((sess_n, emb_dim), dtype=DTYPE, device=device)
    x_query = torch.tensor(q_emb, dtype=DTYPE, device=device)
    x_llm = torch.tensor(l_emb, dtype=DTYPE, device=device)
    x_response = ratings * torch.ones((len(responses), emb_dim), dtype=DTYPE, device=device)

    nodes: NodeDict = {
        "user": x_user,
        "session": x_session,
        "response": x_response,
        "query": x_query,
        "llm": x_llm
    }

    config = HeteroFeature(
        num_users=len(users),
        num_sessions=sess_n,
        num_queries=len(q_emb),
        num_responses=len(responses),
        num_llms=len(l_emb),
        user_emb=EmbInit.ZEROS,
        session_emb=EmbInit.ZEROS,
        response_emb=EmbInit.ZEROS,
        llm_plm_emb=x_llm,
        query_emb=x_query,
        emb_dim=emb_dim,
        plm_name=plm,
        plm_encode=(make_plm_encode(plm) if plm is not None else None),
        aggregation_type="mean",
    )

    return (
        config,
        nodes,
        edge_index_dict,
        users,
        queries,
        responses,
        ratings,
        llms,
        meta,
        device
    )


# --- Build/load wrapper ---

def build_config(path: str, ckpt_path: str = None):
    """
    Construct the configuration and graph structures from a JSONL file (with optional checkpoint saving)
    or load them from an existing checkpoint.
    """
    device = _default_device()

    if path.endswith(JSONL_SUFFIX):
        dataset_name = os.path.basename(os.path.dirname(path))
        result = build_config_from_jsonl(path)
        (config, nodes, edge_index_dict,
         user_dict, query_dict, response_dict,
         ratings, llm_dict, metadata, device) = result

        if ckpt_path is not None:
            # If `ckpt_path` ends with `.pt`, treat it as a file path; otherwise treat it as a directory.
            if ckpt_path.endswith(".pt"):
                save_path = ckpt_path
                os.makedirs(os.path.dirname(save_path) or ".", exist_ok=True)
            else:
                os.makedirs(ckpt_path, exist_ok=True)
                save_path = os.path.join(ckpt_path, f"{dataset_name}.pt")

            torch.save({
                "version": "v1",
                "config": {
                    "num_users": config.num_users,
                    "num_sessions": config.num_sessions,
                    "num_queries": config.num_queries,
                    "num_responses": config.num_responses,
                    "num_llms": config.num_llms,
                    "emb_dim": config.emb_dim,
                    "plm_name": config.plm_name,
                    "aggregation_type": config.aggregation_type,
                },
                "nodes": {k: v.cpu() for k, v in nodes.items()},
                "edges": {etype.name: v.cpu() for etype, v in edge_index_dict.items()},
                "user_dict": user_dict,
                "query_dict": query_dict,
                "response_dict": response_dict,
                "llm_dict": llm_dict,
                "metadata": list(metadata),
                "ratings": ratings.cpu(),
            }, save_path)

        return result

    # Load branch remains unchanged.
    if os.path.isdir(path):
        dataset_name = os.path.basename(os.path.normpath(path))
        ckpt_file = os.path.join(path, f"{dataset_name}.pt")
    else:
        ckpt_file = path

    if not os.path.exists(ckpt_file):
        raise FileNotFoundError(f"No checkpoint found at {ckpt_file}")

    ckpt = torch.load(ckpt_file, map_location=device)
    cfg = ckpt["config"]

    nodes: NodeDict = {k: v.to(device) for k, v in ckpt["nodes"].items()}
    config = HeteroFeature(
        num_users=cfg["num_users"],
        num_sessions=cfg["num_sessions"],
        num_queries=cfg["num_queries"],
        num_responses=cfg["num_responses"],
        num_llms=cfg["num_llms"],
        query_emb=nodes["query"],
        llm_plm_emb=nodes["llm"],
        emb_dim=cfg["emb_dim"],
        plm_name=cfg["plm_name"],
        plm_encode=(make_plm_encode(cfg["plm_name"]) if cfg["plm_name"] is not None else None),
        aggregation_type=cfg["aggregation_type"],
    )

    edges: EdgeIndexDict = {HeteroEdges[name]: v.to(device) for name, v in ckpt["edges"].items()}
    metadata = set(tuple(map(tuple, x)) for x in ckpt["metadata"])
    ratings = ckpt["ratings"].to(device)

    return (
        config, nodes, edges,
        ckpt["user_dict"], ckpt["query_dict"], ckpt["response_dict"],
        ratings, ckpt["llm_dict"], metadata, device,
    )


# --- Sampling and PyG graph construction ---

def sample_metadata(
    metadata: Set[Tuple[InteractionUnit, InteractionUnit]],
    visible_count: int = 256,
    predict_count: int = 32,
    min_record_per_user: int = 10,
    seed: int = None
) -> Tuple[List[Tuple[InteractionUnit, InteractionUnit]], List[Tuple[InteractionUnit, InteractionUnit]]]:
    """
    Partition the metadata set into visible and prediction subsets while enforcing a per-user minimum.

    Returns a tuple `(visible_list, predict_list)` of interaction pairs.
    """
    rnd = random.Random(seed)
    metadata_list = list(metadata)
    total = len(metadata_list)
    assert visible_count + predict_count <= total, \
        f"visible_count({visible_count}) + predict_count({predict_count}) > total({total})"

    user_to_entries: defaultdict[int, List[Tuple[InteractionUnit, InteractionUnit]]] = defaultdict(list)
    for e in metadata_list:
        user_to_entries[e[0][0]].append(e)

    visible_set = set()
    pool: List[Tuple[InteractionUnit, InteractionUnit]] = []
    for u, entries in user_to_entries.items():
        if len(entries) < min_record_per_user:
            raise AssertionError(f"User {u} has only {len(entries)} records < min_record_per_user={min_record_per_user}")
        sampled = rnd.sample(entries, min_record_per_user)
        visible_set.update(sampled)
        pool.extend(x for x in entries if x not in sampled)

    visible_list = list(visible_set)
    if len(visible_list) > visible_count:
        rnd.shuffle(visible_list)
        overflow = visible_list[visible_count:]
        visible_list = visible_list[:visible_count]
        pool.extend(overflow)
    elif len(visible_list) < visible_count:
        need = visible_count - len(visible_list)
        if len(pool) < need:
            raise AssertionError("Not enough pool entries to reach visible_count.")
        rnd.shuffle(pool)
        visible_list += pool[:need]
        pool = pool[need:]

    remaining = pool if len(pool) >= predict_count else (pool + [e for e in metadata_list if e not in visible_set and e not in pool])
    assert len(remaining) >= predict_count, "Not enough remaining entries to sample prediction set."
    predict_list = rnd.sample(remaining, predict_count)
    return visible_list, predict_list


def build_hetero_data(nodes: NodeDict, edge_index_dict: EdgeIndexDict) -> HeteroData:
    """Instantiate a PyTorch Geometric `HeteroData` object from node feature tensors and edge indices."""
    data = HeteroData()
    for ntype, x in nodes.items():
        data[ntype].x = x
    for etype, edge_index in edge_index_dict.items():
        src, rel, dst = etype.value
        data[(src, rel, dst)].edge_index = edge_index
    return data
